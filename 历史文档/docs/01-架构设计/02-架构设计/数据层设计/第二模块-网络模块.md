
我们将从 **协议 (DTO)**、**接口 (API)**、**引擎 (Client Config)** 三个层面来设计。

-----

### 1\. 传输层协议设计 (DTOs)

**位置**：`data/remote/model`

我们要定义一套符合 "OpenAI Chat Completion API" 标准的 JSON 数据结构。目前市面上 99% 的大模型服务商都兼容这个标准接口。

**设计原则**：

  * **物理隔离**：DTO 绝不允许出现在 Domain 层。网络数据结构变了，不应该影响业务逻辑。
  * **字段映射**：使用 Gson 的 `@SerializedName` 处理字段名差异（虽然 OpenAI 很标准，但养成好习惯很重要）。

**核心类结构**：

1.  **`ChatRequestDto`** (发送给 AI 的包)

      * `model`: String (e.g., "gpt-3.5-turbo", "deepseek-chat")
      * `messages`: List\<`MessageDto`\>
      * `temperature`: Double (设为 0.7，控制回复的随机性)
      * `stream`: Boolean (MVP 设为 false，做一次性请求，降低处理难度)

2.  **`MessageDto`** (消息单元)

      * `role`: String ("system" | "user" | "assistant")
      * `content`: String

3.  **`ChatResponseDto`** (AI 回回来的包)

      * `id`: String
      * `choices`: List\<`ChoiceDto`\> (通常我们只取第 0 个)
      * `usage`: `UsageDto` (可选，统计 token 消耗)

-----

### 2\. 接口层设计 (Retrofit Interface)

**位置**：`data/remote/api/OpenAiApi.kt`

这里是定义 HTTP 动作的地方。

**核心挑战**：Retrofit 通常要求在初始化时写死 `baseUrl`。但我们的用户可能今天用 OpenAI，明天用 DeepSeek。
**解决方案**：使用 Retrofit 的 **`@Url`** 注解实现“运行时动态路由”。

**代码设计概览**：

```kotlin
interface OpenAiApi {
    @POST
    suspend fun chatCompletion(
        // 1. 动态 URL：由 Repository 层决定去哪个服务器
        @Url fullUrl: String, 
        
        // 2. 动态 Header：由 Repository 层从加密存储中取出 Key
        @HeaderMap headers: Map<String, String>, 
        
        // 3. 请求体
        @Body request: ChatRequestDto
    ): ChatResponseDto
}
```

-----

### 3\. 引擎配置设计 (DI / OkHttp Config)

**位置**：`di/NetworkModule.kt`

这是 **连接池** 和 **超时策略** 的配置中心。对于 LLM 应用，这里有几个**生死攸关**的参数。

1.  **超时设置 (Timeouts)**：

      * 普通的 App 接口超时通常是 10秒。
      * **LLM 是个慢郎中**：生成一段长回复可能需要 20-40 秒。
      * **策略**：`connectTimeout` = 30s, `readTimeout` = 60s, `writeTimeout` = 30s。如果设短了，用户会经常看到 `SocketTimeoutException`。

2.  **日志拦截 (Logging)**：

      * 我们需要看到发出去的 JSON 和回来的 JSON，方便调试。
      * **策略**：添加 `HttpLoggingInterceptor`，但仅在 `DEBUG` 模式下开启 `Level.BODY`。

-----

### 4\. 业务落地逻辑 (Repository Implementation)

**位置**：`data/repository/AiRepositoryImpl.kt`

这是这一层的“大脑”，负责把上面所有东西串起来。

**工作流程 (The Pipeline)**：

1.  **路由选择 (Routing)**：

      * 从 `SettingsRepo` 读取用户选的服务商（Provider）。
      * *Switch Case*：
          * 如果是 "OpenAI" -\> URL = `https://api.openai.com/v1/chat/completions`
          * 如果是 "DeepSeek" -\> URL = `https://api.deepseek.com/chat/completions`

2.  **鉴权注入 (Auth)**：

      * 从 `SettingsRepo` 读取解密后的 API Key。
      * 构造 Header: `{"Authorization": "Bearer $apiKey"}`。

3.  **数据转换 (Mapping)**：

      * 把 Domain 层的 `profile` (画像) 和 `tags` (策略) 拼成一个 `system` 角色的 Message。
      * 把 Domain 层的 `context` (聊天记录) 拼成 `user` 角色的 Message。

4.  **调用与解析 (Call & Parse)**：

      * 调用 `api.chatCompletion(...)`。
      * 拿到 `response.choices[0].message.content`。
      * 尝试解析这个 Content（因为我们在 Prompt 里要求 AI 返回 JSON 格式的分析结果）。

-----

### 总结：网络模块的“施工图纸”

这个设计对于 MVP 阶段来说是**最稳健**的：

  * **灵活性**：通过 `@Url` 完美解决多服务商切换。
  * **稳定性**：通过加长 OkHttp 超时时间解决 AI 响应慢的问题。
  * **隔离性**：通过 DTO 隔离了网络层变化对业务层的影响。

