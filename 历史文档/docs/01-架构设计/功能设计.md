---
date_modified: 2025-12-02 19:19:47
---

# 功能设计文档：共情 AI 助手 (MVP v2.0)

### 1. 核心设计哲学

1. **“多渠道喂养，结构化记忆”**：用户通过导入文本、音频、视频等多模态数据，AI 在后台将其清洗为**“客观事实 (Facts)”**和**“主观策略 (Tags)”**两类数据，存入本地大脑。
    
2. **“本地优先，云端增强”**：
    
    - **高频操作（实时检查）**优先走本地规则，零延迟、零成本。
        
    - **低频操作（深度分析）**走云端大模型，高智能。
        
3. **“辅助而非替代”**：AI 提供策略卡片和草稿润色，但最终发送权永远在用户手中。
    

---

### 模块一：核心大脑 (The Brain) - 学习与记忆

**目标：** 构建一个属于该联系人的专属知识库，解决“记不住”和“不懂他”的问题。

#### 1.1 数据喂养机制 (The Feeder)

用户在联系人详情页点击 `[+] 数据喂养`，触发以下流程：

- **A. `[✍️ 手动记录]` (最高权重)**
    
    - **输入：** 用户直接添加标签（如“雷区：不要提钱”）或事实（如“事实：他有一只猫”）。
        
    - **逻辑：** 标记来源为 `MANUAL`，AI 在后续分析中**绝对遵从**，不可覆盖。
        
- **B. `[📄 导入聊天记录]` (文本分析)**
    
    - **输入：** 粘贴文本 或 导入 `.txt` / `.csv`。
        
    - **逻辑：**
        
        1. **脱敏：** 本地正则替换敏感信息。
            
        2. **分析：** 发送给 LLM，指令：“提取性格特征、潜在雷区、和新出现的事实信息”。
            
        3. **入库：** 生成 `AI_INFERRED` 标签，需用户在“新发现”列表中**[确认]**后生效。
            
- **C. `[🎬/🎧 媒体文件分析]` (多模态)**
    
    - **输入：** `.mp3` (语音) 或 `.mp4` (视频)。
        
    - **逻辑：**
        
        1. **本地预判：** 检查文件是否包含音轨。
            
        2. **分流处理：**
            
            - _有声：_ 提取音频 -> 云端 STT (语音转文字) -> 文本分析流程。
                
            - _无声/录屏：_ 提取关键帧 (每5秒一张) -> 云端 Vision (视觉分析) -> 文本分析流程。
                
        3. **结果：** 提取出的信息归档入库，原始大文件处理后**即刻丢弃**，不占用存储。
            

#### 1.2 记忆存储结构 (The Schema)

数据库层面分为两类存储，解决逻辑冲突问题：

1. **客观画像 (ContactProfile - Facts Map):**
    
    - 存储不可变或客观的事实。
        
    - _示例：_ `{"电话": "138...", "住址": "朝阳区", "爱好": "钓鱼", "性格": "吃软不吃硬"}`
        
    - _更新逻辑：_ 新事实追加，冲突事实需用户确认。
        
2. **策略锦囊 (BrainTags):**
    
    - 存储用于决策的红绿灯规则。
        
    - **`[🔴 RISK_RED]` (雷区):** 绝对禁止的话题。 (e.g., "前任", "借钱")
        
    - **`[🟢 STRATEGY_GREEN]` (策略):** 建议切入点。 (e.g., "夸衣品", "聊猫")
        

---

### 模块二：实时辅助 (The Service) - 交互与应用

#### 2.1 “被动守护”模式 (防踩雷 / Gatekeeper)

**修订重点：** 放弃“实时云端监测”，改为“双层漏斗”机制，确保流畅性与隐私。

- **触发：** 用户在输入框输入文本时。
    
- **Layer 1: 本地极速拦截 (Local Fast Match)**
    
    - **机制：** 监听输入内容，实时匹配本地 `RISK_RED` 标签库。
        
    - **延迟：** < 10ms (零网络消耗)。
        
    - **反馈：** 若命中关键词（如“借钱”），悬浮球变红并震动，提示“命中雷区：不要提钱”。
        
- **Layer 2: 云端语义复核 (Cloud Semantic Check) - _可选/按需_**
    
    - **机制：** 仅当用户**停留超过 1.5秒** 或 **手动点击“检查”** 时触发。
        
    - **逻辑：** 将草稿发送给 AI，判断语义风险（如“手头紧” = “借钱”）。
        
    - **反馈：** 若 AI 判定有风险，弹出黄色警告卡。
        

#### 2.2 “主动求助”模式 (AI 军师 / Analyst)

- **触发：** 用户点击悬浮窗 `[💡 帮我分析]`。
    
- **核心流程 (RAG):**
    
    1. **抓取：** 读取屏幕最近 `N` 条上下文（滚动抓取）。
        
    2. **组装：** 拼接 `[脱敏上下文]` + `[Facts事实]` + `[Tags策略]`。
        
    3. **推理：** 调用大模型生成 JSON 结果。
        
- **UI 展示 (AI 策略卡):**
    
    - **状态分析：** 对方当前情绪（焦虑/开心/防御）。
        
    - **核心洞察：** “他正在试探你的底线。”
        
    - **回复建议：** 提供 A/B 两套话术（保守型 vs 进取型）。
        

#### 2.3 交互细节：填充与润色

解决“覆盖冲突”问题：

- **场景：** 用户点击建议回复的 `[↗️ 填充]` 按钮。
    
- **逻辑：**
    
    1. **检测：** 检查原生输入框是否为空。
        
    2. **Case A (为空):** 直接插入文本，光标置于末尾。
        
    3. **Case B (不为空):**
        
        - 弹出微交互菜单：`[覆盖]` 或 `[追加]`。
            
        - 或者：仅复制到剪贴板并 Toast 提示“已复制，请手动粘贴以防覆盖草稿”。
            

---

### 模块三：非功能性需求 (NFR)

1. **隐私脱敏 (Privacy):**
    
    - 所有发送给云端 AI 的文本（无论是分析还是训练），必须先经过 **PrivacyEngine** 处理。
        
    - 正则屏蔽：手机号、身份证、邮箱。
        
    - 字典屏蔽：将联系人真实姓名替换为占位符 (e.g., `[Target_User]`)。
        
2. **网络与成本 (Performance):**
    
    - **被动模式** 必须 99% 依赖本地逻辑。
        
    - **主动模式** 的 API 请求超时设为 5秒，超时自动降级提示“网络波动”。
        

---

Q: 这份更新后的 PRD 最大的改进点是什么？

A: 最大的改进是将“被动模式”从不可落地的“实时云端监测”改为了“本地关键词拦截 + 按需云端语义检查”的双层架构，同时明确了数据结构中“客观事实”与“主观策略”的分离。