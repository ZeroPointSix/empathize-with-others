# TDD-00003 补充说明文档

## 文档信息

- **文档编号**: TDD-00003-补充
- **版本**: v1.0
- **创建日期**: 2025-12-14
- **关联文档**: TDD-00003-联系人画像记忆系统架构设计

---

## 1. 解析逻辑实现补充

### 1.1 DailySummaryEntity解析增强

**问题**: 当前`toDomainModel()`方法中的`newFacts`和`updatedTags`返回空列表，需要从`content`中解析。

**解决方案**: 添加专门的解析辅助方法

```kotlin
/**
 * DailySummaryEntity扩展 - 完整解析实现
 */
fun toDomainModel(moshi: Moshi): DailySummary {
    // 1. 解析keyEvents
    val keyEventsAdapter = moshi.adapter<List<KeyEvent>>(
        Types.newParameterizedType(List::class.java, KeyEvent::class.java)
    )
    val keyEvents = keyEventsAdapter.fromJson(keyEventsJson) ?: emptyList()
    
    // 2. 从content中解析newFacts和updatedTags
    val (newFacts, updatedTags) = parseContentFields(content, moshi)
    
    // 3. 计算relationshipScoreChange和relationshipTrend
    val scoreChange = relationshipScore  // 直接使用存储的值
    val trend = calculateTrend(scoreChange)
    
    return DailySummary(
        id = id,
        contactId = contactId,
        summaryDate = summaryDate,
        content = content,
        keyEvents = keyEvents,
        newFacts = newFacts,
        updatedTags = updatedTags,
        relationshipScoreChange = scoreChange,
        relationshipTrend = trend
    )
}

/**
 * 从content中解析newFacts和updatedTags
 * 
 * AI返回的JSON格式示例：
 * {
 *   "summary": "...",
 *   "keyEvents": [...],
 *   "newFacts": [...],
 *   "updatedTags": [...],
 *   "relationshipScoreChange": 5
 * }
 */
private fun parseContentFields(
    content: String,
    moshi: Moshi
): Pair<List<Fact>, List<TagUpdate>> {
    return try {
        // 尝试解析完整的AI响应JSON
        val jsonAdapter = moshi.adapter<AiSummaryResponse>(AiSummaryResponse::class.java)
        val response = jsonAdapter.fromJson(content)
        
        if (response != null) {
            Pair(response.newFacts, response.updatedTags)
        } else {
            Pair(emptyList(), emptyList())
        }
    } catch (e: Exception) {
        Log.w("DailySummary", "解析content失败，使用空列表", e)
        Pair(emptyList(), emptyList())
    }
}

/**
 * 根据分数变化计算关系趋势
 */
private fun calculateTrend(scoreChange: Int): RelationshipTrend {
    return when {
        scoreChange >= 3 -> RelationshipTrend.IMPROVING
        scoreChange <= -3 -> RelationshipTrend.DECLINING
        else -> RelationshipTrend.STABLE
    }
}

/**
 * AI总结响应的完整数据结构
 * 用于解析AI返回的JSON
 */
@JsonClass(generateAdapter = true)
data class AiSummaryResponse(
    val summary: String,
    val keyEvents: List<KeyEvent>,
    val newFacts: List<Fact>,
    val updatedTags: List<TagUpdate>,
    val relationshipScoreChange: Int,
    val relationshipTrend: String
)
```

### 1.2 数据库存储策略优化

**当前问题**: `content`字段存储完整JSON，但`key_events_json`单独存储，存在冗余。

**优化方案A（推荐）**: 只存储完整JSON到`content`

```kotlin
@Entity(tableName = "daily_summaries")
data class DailySummaryEntity(
    @PrimaryKey(autoGenerate = true)
    @ColumnInfo(name = "id")
    val id: Long = 0,
    
    @ColumnInfo(name = "contact_id")
    val contactId: String,
    
    @ColumnInfo(name = "summary_date")
    val summaryDate: String,
    
    @ColumnInfo(name = "content")
    val content: String,  // 存储完整的AI响应JSON
    
    // 移除key_events_json字段，避免冗余
    
    @ColumnInfo(name = "relationship_score")
    val relationshipScore: Int,
    
    @ColumnInfo(name = "created_at")
    val createdAt: Long
)
```

**优化方案B（当前方案）**: 保持现有结构，但优化存储逻辑

```kotlin
fun DailySummary.toEntity(moshi: Moshi): DailySummaryEntity {
    // 构建完整的AI响应JSON
    val fullResponse = AiSummaryResponse(
        summary = content,
        keyEvents = keyEvents,
        newFacts = newFacts,
        updatedTags = updatedTags,
        relationshipScoreChange = relationshipScoreChange,
        relationshipTrend = relationshipTrend.name
    )
    
    val jsonAdapter = moshi.adapter<AiSummaryResponse>(AiSummaryResponse::class.java)
    val contentJson = jsonAdapter.toJson(fullResponse)
    
    // keyEvents单独存储，便于快速查询
    val keyEventsAdapter = moshi.adapter<List<KeyEvent>>(
        Types.newParameterizedType(List::class.java, KeyEvent::class.java)
    )
    val keyEventsJson = keyEventsAdapter.toJson(keyEvents)
    
    return DailySummaryEntity(
        id = id,
        contactId = contactId,
        summaryDate = summaryDate,
        content = contentJson,
        keyEventsJson = keyEventsJson,
        relationshipScore = relationshipScoreChange,
        createdAt = System.currentTimeMillis()
    )
}
```

---

## 2. 性能优化策略（中优先级）

### 2.1 分页加载对话记录

**问题**: 大量对话记录可能导致内存压力。

**解决方案**: 使用Paging 3库实现分页加载

```kotlin
/**
 * ConversationLogDao - 添加分页支持
 */
@Dao
interface ConversationLogDao {
    
    /**
     * 分页查询对话记录
     * 使用Paging 3库
     */
    @Query("""
        SELECT * FROM conversation_logs 
        WHERE contact_id = :contactId 
        ORDER BY timestamp DESC
    """)
    fun getLogsPaged(contactId: String): PagingSource<Int, ConversationLogEntity>
    
    /**
     * 分页查询未总结的对话
     */
    @Query("""
        SELECT * FROM conversation_logs 
        WHERE is_summarized = 0 AND timestamp >= :sinceTimestamp
        ORDER BY timestamp ASC
        LIMIT :limit OFFSET :offset
    """)
    suspend fun getUnsummarizedLogsPaged(
        sinceTimestamp: Long,
        limit: Int = 50,
        offset: Int = 0
    ): List<ConversationLogEntity>
}

/**
 * ConversationRepository - 添加分页方法
 */
interface ConversationRepository {
    
    /**
     * 获取分页的对话记录Flow
     */
    fun getLogsPagedFlow(contactId: String): Flow<PagingData<ConversationLog>>
    
    /**
     * 批量获取未总结对话（分页）
     */
    suspend fun getUnsummarizedLogsBatch(
        sinceTimestamp: Long,
        batchSize: Int = 50
    ): Flow<List<ConversationLog>>
}

/**
 * ConversationRepositoryImpl - 实现分页
 */
class ConversationRepositoryImpl @Inject constructor(
    private val conversationLogDao: ConversationLogDao
) : ConversationRepository {
    
    override fun getLogsPagedFlow(contactId: String): Flow<PagingData<ConversationLog>> {
        return Pager(
            config = PagingConfig(
                pageSize = 20,
                enablePlaceholders = false,
                prefetchDistance = 5
            ),
            pagingSourceFactory = { conversationLogDao.getLogsPaged(contactId) }
        ).flow.map { pagingData ->
            pagingData.map { it.toDomainModel() }
        }
    }
    
    override suspend fun getUnsummarizedLogsBatch(
        sinceTimestamp: Long,
        batchSize: Int
    ): Flow<List<ConversationLog>> = flow {
        var offset = 0
        var hasMore = true
        
        while (hasMore) {
            val batch = conversationLogDao.getUnsummarizedLogsPaged(
                sinceTimestamp = sinceTimestamp,
                limit = batchSize,
                offset = offset
            )
            
            if (batch.isNotEmpty()) {
                emit(batch.map { it.toDomainModel() })
                offset += batchSize
            } else {
                hasMore = false
            }
        }
    }
}
```

### 2.2 使用Flow避免内存泄漏

**问题**: 长时间运行的协程可能导致内存泄漏。

**解决方案**: 使用Flow和正确的作用域管理

```kotlin
/**
 * SummarizeDailyConversationsUseCase - Flow优化版本
 */
class SummarizeDailyConversationsUseCase @Inject constructor(
    private val conversationRepository: ConversationRepository,
    private val contactRepository: ContactRepository,
    private val brainTagRepository: BrainTagRepository,
    private val dailySummaryRepository: DailySummaryRepository,
    private val aiRepository: AiRepository,
    private val memoryPreferences: MemoryPreferences
) {
    
    /**
     * 执行每日总结（Flow版本）
     * 使用Flow避免一次性加载所有数据
     */
    suspend operator fun invoke(): Result<SummaryResult> {
        return withContext(Dispatchers.IO) {
            try {
                val lastSummaryDate = memoryPreferences.getLastSummaryDate()
                val today = getCurrentDateString()
                
                if (lastSummaryDate == today) {
                    return@withContext Result.success(SummaryResult(skipped = true))
                }
                
                val sevenDaysAgo = System.currentTimeMillis() - 7 * 24 * 60 * 60 * 1000L
                
                var successCount = 0
                var failedCount = 0
                var usedFallback = false
                
                // 使用Flow分批处理，避免内存压力
                conversationRepository.getUnsummarizedLogsBatch(sevenDaysAgo)
                    .collect { batch ->
                        // 按联系人和日期分组
                        val groupedLogs = batch
                            .groupBy { it.contactId }
                            .flatMap { (contactId, logs) ->
                                logs.groupBy { it.getDateString() }
                                    .map { (date, dateLogs) -> 
                                        Triple(contactId, date, dateLogs) 
                                    }
                            }
                        
                        // 处理每组
                        groupedLogs.forEach { (contactId, date, logs) ->
                            try {
                                val result = summarizeForContact(contactId, logs, date)
                                if (result.usedFallback) usedFallback = true
                                successCount++
                            } catch (e: Exception) {
                                Log.e("DailySummary", "Failed for $contactId on $date", e)
                                failedCount++
                            }
                        }
                    }
                
                memoryPreferences.setLastSummaryDate(today)
                
                Result.success(SummaryResult(
                    successCount = successCount,
                    failedCount = failedCount,
                    usedFallback = usedFallback
                ))
            } catch (e: Exception) {
                Result.failure(e)
            }
        }
    }
}
```

### 2.3 定期清理过期数据

**问题**: 对话记录和总结数据会不断累积。

**解决方案**: 实现自动清理机制

```kotlin
/**
 * DataCleanupManager - 数据清理管理器
 */
@Singleton
class DataCleanupManager @Inject constructor(
    private val conversationRepository: ConversationRepository,
    private val memoryPreferences: MemoryPreferences
) {
    
    companion object {
        private const val CLEANUP_INTERVAL_DAYS = 7  // 每7天清理一次
        private const val RETENTION_DAYS = 30  // 保留30天的已总结对话
    }
    
    /**
     * 检查并执行清理
     * 在Application.onCreate()中调用
     */
    suspend fun checkAndCleanup() {
        val lastCleanupDate = memoryPreferences.getLastCleanupDate()
        val today = getCurrentDateString()
        
        if (shouldCleanup(lastCleanupDate, today)) {
            performCleanup()
            memoryPreferences.setLastCleanupDate(today)
        }
    }
    
    private fun shouldCleanup(lastCleanupDate: String?, today: String): Boolean {
        if (lastCleanupDate == null) return true
        
        val lastDate = parseDate(lastCleanupDate)
        val currentDate = parseDate(today)
        val daysDiff = ChronoUnit.DAYS.between(lastDate, currentDate)
        
        return daysDiff >= CLEANUP_INTERVAL_DAYS
    }
    
    private suspend fun performCleanup() {
        val retentionTimestamp = System.currentTimeMillis() - 
            RETENTION_DAYS * 24 * 60 * 60 * 1000L
        
        conversationRepository.cleanupOldSummarizedLogs(retentionTimestamp)
            .onSuccess { count ->
                Log.i("DataCleanup", "清理了 $count 条过期对话记录")
            }
            .onFailure { error ->
                Log.e("DataCleanup", "清理失败", error)
            }
    }
}

/**
 * MemoryPreferences - 添加清理日期记录
 */
class MemoryPreferences @Inject constructor(
    @ApplicationContext private val context: Context
) {
    private val prefs = context.getSharedPreferences("memory_settings", Context.MODE_PRIVATE)
    
    companion object {
        private const val KEY_LAST_CLEANUP_DATE = "last_cleanup_date"
    }
    
    fun getLastCleanupDate(): String? {
        return prefs.getString(KEY_LAST_CLEANUP_DATE, null)
    }
    
    fun setLastCleanupDate(date: String) {
        prefs.edit().putString(KEY_LAST_CLEANUP_DATE, date).apply()
    }
}

/**
 * EmpathyApplication - 集成清理逻辑
 */
class EmpathyApplication : Application() {
    
    @Inject
    lateinit var dataCleanupManager: DataCleanupManager
    
    override fun onCreate() {
        super.onCreate()
        
        // 启动清理任务
        lifecycleScope.launch {
            dataCleanupManager.checkAndCleanup()
        }
    }
}
```

---

## 3. 错误恢复机制完善（中优先级）

### 3.1 失败任务持久化存储

**问题**: 应用重启后，失败的总结任务会丢失。

**解决方案**: 使用数据库持久化失败任务

```kotlin
/**
 * FailedSummaryTaskEntity - 失败任务实体
 */
@Entity(
    tableName = "failed_summary_tasks",
    indices = [
        Index(value = ["contact_id"]),
        Index(value = ["summary_date"]),
        Index(value = ["retry_count"])
    ]
)
data class FailedSummaryTaskEntity(
    @PrimaryKey(autoGenerate = true)
    @ColumnInfo(name = "id")
    val id: Long = 0,
    
    @ColumnInfo(name = "contact_id")
    val contactId: String,
    
    @ColumnInfo(name = "summary_date")
    val summaryDate: String,
    
    @ColumnInfo(name = "error_message")
    val errorMessage: String?,
    
    @ColumnInfo(name = "retry_count")
    val retryCount: Int = 0,
    
    @ColumnInfo(name = "last_retry_timestamp")
    val lastRetryTimestamp: Long,
    
    @ColumnInfo(name = "created_at")
    val createdAt: Long
)

/**
 * FailedSummaryTaskDao
 */
@Dao
interface FailedSummaryTaskDao {
    
    @Insert(onConflict = OnConflictStrategy.REPLACE)
    suspend fun insert(task: FailedSummaryTaskEntity): Long
    
    @Query("SELECT * FROM failed_summary_tasks WHERE retry_count < :maxRetries ORDER BY created_at ASC")
    suspend fun getPendingTasks(maxRetries: Int = 3): List<FailedSummaryTaskEntity>
    
    @Query("UPDATE failed_summary_tasks SET retry_count = :retryCount, last_retry_timestamp = :timestamp WHERE id = :taskId")
    suspend fun updateRetryCount(taskId: Long, retryCount: Int, timestamp: Long)
    
    @Query("DELETE FROM failed_summary_tasks WHERE id = :taskId")
    suspend fun delete(taskId: Long)
    
    @Query("DELETE FROM failed_summary_tasks WHERE retry_count >= :maxRetries")
    suspend fun deleteExhaustedTasks(maxRetries: Int = 3)
}

/**
 * FailedTaskRepository
 */
interface FailedTaskRepository {
    suspend fun saveFailedTask(task: FailedSummaryTask): Result<Long>
    suspend fun getPendingTasks(): Result<List<FailedSummaryTask>>
    suspend fun markTaskRetried(taskId: Long): Result<Unit>
    suspend fun deleteTask(taskId: Long): Result<Unit>
    suspend fun cleanupExhaustedTasks(): Result<Int>
}
```

### 3.2 应用重启后的任务恢复

**解决方案**: 在Application启动时恢复失败任务

```kotlin
/**
 * SummarizeDailyConversationsUseCase - 添加失败任务恢复
 */
class SummarizeDailyConversationsUseCase @Inject constructor(
    private val conversationRepository: ConversationRepository,
    private val contactRepository: ContactRepository,
    private val brainTagRepository: BrainTagRepository,
    private val dailySummaryRepository: DailySummaryRepository,
    private val aiRepository: AiRepository,
    private val memoryPreferences: MemoryPreferences,
    private val failedTaskRepository: FailedTaskRepository  // 新增
) {
    
    /**
     * 恢复失败的任务
     * 在Application启动时调用
     */
    suspend fun recoverFailedTasks(): Result<RecoveryResult> {
        return withContext(Dispatchers.IO) {
            try {
                val pendingTasks = failedTaskRepository.getPendingTasks().getOrThrow()
                
                var successCount = 0
                var failedCount = 0
                
                pendingTasks.forEach { task ->
                    try {
                        // 重新获取对话记录
                        val logs = conversationRepository.getLogsByContactAndDate(
                            task.contactId,
                            task.date
                        ).getOrThrow()
                        
                        if (logs.isNotEmpty()) {
                            // 重试总结
                            summarizeForContact(task.contactId, logs, task.date)
                            
                            // 成功后删除失败任务
                            failedTaskRepository.deleteTask(task.id)
                            successCount++
                        }
                    } catch (e: Exception) {
                        Log.e("TaskRecovery", "恢复任务失败: ${task.contactId}", e)
                        
                        // 更新重试次数
                        failedTaskRepository.markTaskRetried(task.id)
                        failedCount++
                    }
                }
                
                // 清理已达到最大重试次数的任务
                failedTaskRepository.cleanupExhaustedTasks()
                
                Result.success(RecoveryResult(
                    successCount = successCount,
                    failedCount = failedCount
                ))
            } catch (e: Exception) {
                Result.failure(e)
            }
        }
    }
    
    /**
     * 执行总结时保存失败任务
     */
    private suspend fun summarizeForContact(
        contactId: String,
        logs: List<ConversationLog>,
        date: String
    ): SummarizeResult {
        return try {
            // 执行总结逻辑...
            SummarizeResult(success = true, usedFallback = false)
        } catch (e: Exception) {
            // 保存失败任务
            failedTaskRepository.saveFailedTask(
                FailedSummaryTask(
                    contactId = contactId,
                    date = date,
                    errorMessage = e.message,
                    retryCount = 0,
                    lastRetryTimestamp = System.currentTimeMillis()
                )
            )
            
            throw e
        }
    }
}

/**
 * EmpathyApplication - 启动时恢复任务
 */
class EmpathyApplication : Application() {
    
    @Inject
    lateinit var summarizeUseCase: SummarizeDailyConversationsUseCase
    
    override fun onCreate() {
        super.onCreate()
        
        // 恢复失败的任务
        lifecycleScope.launch {
            summarizeUseCase.recoverFailedTasks()
                .onSuccess { result ->
                    Log.i("TaskRecovery", "恢复完成: 成功${result.successCount}, 失败${result.failedCount}")
                }
                .onFailure { error ->
                    Log.e("TaskRecovery", "恢复失败", error)
                }
        }
    }
}

data class RecoveryResult(
    val successCount: Int,
    val failedCount: Int
)
```

---

## 4. 数据库Migration更新

由于添加了`failed_summary_tasks`表，需要更新Migration脚本：

```kotlin
/**
 * Migration 4→5
 * 添加失败任务表
 */
val MIGRATION_4_5 = object : Migration(4, 5) {
    override fun migrate(database: SupportSQLiteDatabase) {
        // 创建failed_summary_tasks表
        database.execSQL("""
            CREATE TABLE IF NOT EXISTS failed_summary_tasks (
                id INTEGER PRIMARY KEY AUTOINCREMENT NOT NULL,
                contact_id TEXT NOT NULL,
                summary_date TEXT NOT NULL,
                error_message TEXT,
                retry_count INTEGER NOT NULL DEFAULT 0,
                last_retry_timestamp INTEGER NOT NULL,
                created_at INTEGER NOT NULL
            )
        """)
        
        // 创建索引
        database.execSQL("CREATE INDEX idx_failed_task_contact ON failed_summary_tasks(contact_id)")
        database.execSQL("CREATE INDEX idx_failed_task_date ON failed_summary_tasks(summary_date)")
        database.execSQL("CREATE INDEX idx_failed_task_retry ON failed_summary_tasks(retry_count)")
    }
}
```

---

## 5. 依赖注入更新

```kotlin
/**
 * MemoryModule - 添加新的依赖
 */
@Module
@InstallIn(SingletonComponent::class)
object MemoryModule {
    
    @Provides
    @Singleton
    fun provideDataCleanupManager(
        conversationRepository: ConversationRepository,
        memoryPreferences: MemoryPreferences
    ): DataCleanupManager {
        return DataCleanupManager(conversationRepository, memoryPreferences)
    }
    
    @Provides
    @Singleton
    fun provideFailedTaskRepository(
        failedTaskDao: FailedSummaryTaskDao
    ): FailedTaskRepository {
        return FailedTaskRepositoryImpl(failedTaskDao)
    }
}

/**
 * DatabaseModule - 添加新的DAO
 */
@Module
@InstallIn(SingletonComponent::class)
object DatabaseModule {
    
    @Provides
    fun provideFailedSummaryTaskDao(database: AppDatabase): FailedSummaryTaskDao {
        return database.failedSummaryTaskDao()
    }
}
```

---

## 6. 总结

本补充文档提供了以下优化：

### 高优先级
- ✅ 代码格式检查（已确认正确）
- ✅ 补充DailySummaryEntity解析逻辑
- ✅ 优化数据存储策略

### 中优先级
- ✅ 分页加载对话记录（使用Paging 3）
- ✅ 使用Flow避免内存泄漏
- ✅ 定期清理过期数据
- ✅ 失败任务持久化存储
- ✅ 应用重启后任务恢复

这些优化将显著提升系统的健壮性和性能表现。

---

**文档完成日期**: 2025-12-14  
**下一步**: 将这些优化整合到实现代码中
